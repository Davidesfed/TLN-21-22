{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Tagging con Viterbi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni accessorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(number):\n",
    "    if number == 0:\n",
    "        number += 0.0000000001\n",
    "    return math.log(number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(path):\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        return parse_conllu(f.readlines())\n",
    "\n",
    "def parse_conllu(lines):\n",
    "    result = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        if len(line) <= 1:\n",
    "            result.append(sentence.copy())\n",
    "            sentence = []\n",
    "        else:\n",
    "            token = parse_conllu_token(line)\n",
    "            sentence.append(token)\n",
    "    return result\n",
    "\n",
    "def parse_conllu_token(line):\n",
    "    line = line.strip('\\n').split('\\t')\n",
    "    tag = line[2]\n",
    "    if tag != 'O':\n",
    "        tag = tag[2:]\n",
    "    return (line[1], tag)\n",
    "\n",
    "lang = 'en'\n",
    "corpus = get_corpus(f'data/{lang}/train.conllu')\n",
    "tagset = ['O', 'ORG', 'LOC', 'PER', 'MISC']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagger():\n",
    "    def __init__(self, model, algorithm):\n",
    "        self.model = model\n",
    "        self.algorithm = algorithm\n",
    "        self.tagset = model.tagset\n",
    "\n",
    "    def tag_sentence(self, sentence):\n",
    "        if sentence.__class__ == str:\n",
    "            sentence = sentence.split()\n",
    "        return self.algorithm(self.model, sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    def __init__(self, corpus, tagset):\n",
    "        self.tagset = tagset\n",
    "        self.punctuation_signs = [',', '.', '-', ':', '\\'', '(', ')', '\"']\n",
    "        self.vocabulary, self.tag_occurrences = self._build_vocabulary_and_tag_count(corpus)\n",
    "        self.start_prob = self.compute_start_prob(corpus)\n",
    "        self.end_prob = self.compute_end_prob(corpus)\n",
    "        self.transition_prob = self.compute_transition_prob(corpus)\n",
    "        self.emission_prob = self.compute_emission_prob(corpus)\n",
    "        self.smoothing_strategy = 'always_o'\n",
    "    \n",
    "    def _build_vocabulary_and_tag_count(self, corpus):\n",
    "        tag_occurrences = dict((tag,0) for tag in self.tagset)\n",
    "        vocabulary = set()\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                vocabulary.add(token[0].lower())\n",
    "                tag_occurrences[token[1]] += 1\n",
    "        return list(vocabulary), tag_occurrences\n",
    "\n",
    "    def compute_start_prob(self, corpus):\n",
    "        count_tag = dict((tag,0) for tag in self.tagset)\n",
    "        for sent in corpus:\n",
    "            tag = sent[0][1]\n",
    "            count_tag[tag] += 1\n",
    "        n = len(corpus)\n",
    "        return dict((tag,count/n) for tag,count in count_tag.items())\n",
    "\n",
    "    def compute_transition_prob(self, corpus):\n",
    "        # Inizializzazione dei dizionari\n",
    "        count_tag = dict(((tag1, tag2),0) for tag1 in self.tagset for tag2 in self.tagset)\n",
    "        total = dict((tag, 0) for tag in self.tagset)\n",
    "    \n",
    "        # Conta delle coppie di tag\n",
    "        for sent in corpus:\n",
    "            for i in range(len(sent)-1):\n",
    "                tag1 = sent[i][1]\n",
    "                total[tag1] += 1\n",
    "                tag2 = sent[i+1][1]\n",
    "                key = (tag1, tag2)\n",
    "                count_tag[key] += 1\n",
    "\n",
    "        # Calcolo delle frequenze\n",
    "        for tag1 in self.tagset:\n",
    "            for tag2 in self.tagset:\n",
    "                count_tag[(tag1,tag2)] = count_tag[(tag1,tag2)]/total[tag1]\n",
    "        return count_tag\n",
    "\n",
    "    def compute_end_prob(self, corpus):\n",
    "        count_tag = dict((tag,0) for tag in self.tagset)\n",
    "        for sent in corpus:\n",
    "            tag = self._get_last_tag(sent)\n",
    "            count_tag[tag] += 1\n",
    "        n = len(corpus)\n",
    "        return dict((tag, count/n) for tag,count in count_tag.items())\n",
    "\n",
    "    def _get_last_tag(self, sent):\n",
    "        for i, token in enumerate(reversed(sent)):\n",
    "            if token[0] not in self.punctuation_signs:\n",
    "                return token[1]\n",
    "\n",
    "    def compute_emission_prob(self, corpus):\n",
    "        # Inizializzazione\n",
    "        count_dict = dict()\n",
    "        for word in self.vocabulary:\n",
    "            for tag in self.tagset:\n",
    "                key = (word,tag)\n",
    "                count_dict[key] = 0\n",
    "\n",
    "        # Conteggio\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                word, tag = token\n",
    "                key = (word.lower(), tag)\n",
    "                count_dict[key] += 1\n",
    "\n",
    "        # Calcolo delle frequenze\n",
    "        for word, tag in count_dict:\n",
    "            n = self.tag_occurrences[tag]\n",
    "            count_dict[(word,tag)] = count_dict[(word,tag)]/n\n",
    "        return count_dict\n",
    "\n",
    "    def get_start_prob(self, tag):\n",
    "        return self.start_prob[tag]\n",
    "\n",
    "    def get_transition_prob(self, tag1, tag2):\n",
    "        return self.transition_prob[(tag1, tag2)]\n",
    "\n",
    "    def get_end_prob(self, tag):\n",
    "        return self.end_prob[tag]\n",
    "\n",
    "    def get_emission_prob(self, word, tag):\n",
    "        if word in self.vocabulary:\n",
    "            return self.emission_prob[(word.lower(),tag)]\n",
    "        if self.smoothing_strategy == 'always_o':\n",
    "            return 1.0 if tag == 'O' else 0.0\n",
    "        if self.smoothing_strategy == 'misc_or_o':\n",
    "            return 0.5 if tag in ['MISC', 'O'] else 0.0\n",
    "        if self.smoothing_strategy == 'uniform':\n",
    "            return 1/len(self.tagset)\n",
    "\n",
    "    def set_smoothing_strategy(self, strategy):\n",
    "        if strategy.lower() in ['always_o', 'misc_or_o', 'uniform']:\n",
    "            self.smoothing_strategy = strategy.lower()\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect smoothing strategy\")\n",
    "\n",
    "model = HiddenMarkovModel(corpus, tagset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(model, sentence):\n",
    "    viterbi_matrix, backpointer = inizialitazion_step(model, sentence)\n",
    "    for t in range(1,len(sentence)):\n",
    "        for i in range(len(model.tagset)):\n",
    "            viterbi_matrix[i][t], backpointer[i][t] = compute_max(model, viterbi_matrix, sentence[t], t, i)\n",
    "    viterbi_matrix[-1][-1], backpointer[-1][-1] = termination_step(model, viterbi_matrix)\n",
    "    result = backtrace(backpointer, model.tagset)\n",
    "    return result\n",
    "\n",
    "def inizialitazion_step(model, sentence):\n",
    "    tagset = model.tagset\n",
    "    viterbi_matrix = [[0 for _ in range(len(sentence))] for _ in range(len(tagset)+1)]\n",
    "    backpointer = [[-1 for _ in range(len(sentence))] for _ in range(len(tagset)+1)]\n",
    "    for i, tag in enumerate(tagset):\n",
    "        start_prob = model.get_start_prob(tag)\n",
    "        emission_prob = model.get_emission_prob(sentence[0], tag)\n",
    "        viterbi_matrix[i][0] = log(start_prob * emission_prob)\n",
    "        backpointer[i][0] = 0\n",
    "    return viterbi_matrix, backpointer\n",
    "\n",
    "def compute_max(model, viterbi_matrix, word, t, i):\n",
    "    tagset = model.tagset\n",
    "    max_prob = {'log_prob': -math.inf, 'tag':'-'}\n",
    "    for j in range(len(tagset)):\n",
    "        transition_prob = model.get_transition_prob(tagset[j], tagset[i])\n",
    "        emission_prob = model.get_emission_prob(word, tagset[i])\n",
    "        log_prob = viterbi_matrix[j][t-1] + log(transition_prob * emission_prob)\n",
    "        if log_prob > max_prob['log_prob']:\n",
    "            max_prob = {'log_prob': log_prob, 'tag': tagset[j]}\n",
    "    return max_prob['log_prob'], max_prob['tag']\n",
    "\n",
    "def termination_step(model, viterbi_matrix):\n",
    "    tagset = model.tagset\n",
    "    max_prob = {'log_prob': -math.inf, 'tag':'-'}\n",
    "    for j in range(len(tagset)):\n",
    "        end_prob = model.get_end_prob(tagset[j])\n",
    "        log_prob = viterbi_matrix[j][-1] + log(end_prob)\n",
    "        if log_prob > max_prob['log_prob']:\n",
    "            max_prob = {'log_prob': log_prob, 'tag': tagset[j]}\n",
    "    return max_prob['log_prob'], max_prob['tag']\n",
    "\n",
    "def backtrace(backpointer, tagset):\n",
    "    tags = [backpointer[-1][-1]]\n",
    "    for t in range(len(backpointer[0])-1, 0, -1):\n",
    "        tag = tags[-1]\n",
    "        tag_idx = tagset.index(tag)\n",
    "        tags.append(backpointer[tag_idx][t])\n",
    "    return list(reversed(tags))\n",
    "\n",
    "hmm_viterbi = Tagger(model, viterbi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "    def __init__(self, corpus, tagset):\n",
    "        self.tagset = tagset\n",
    "        self.vocabulary = self.build_vocabulary(corpus)\n",
    "        self.frequencies = self.compute_frequencies(corpus)\n",
    "\n",
    "    def build_vocabulary(self, corpus):\n",
    "        vocabulary = set()\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                vocabulary.add(token[0].lower())\n",
    "        return list(vocabulary)\n",
    "    \n",
    "    def compute_frequencies(self, corpus):\n",
    "        word_dict = dict((tag, 0) for tag in self.tagset)\n",
    "        freq_dict = dict((word, word_dict.copy()) for word in self.vocabulary)\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                freq_dict[token[0].lower()][token[1]] += 1\n",
    "        return freq_dict\n",
    "    \n",
    "    def assign_tag(self, word):\n",
    "        if word.lower() not in self.vocabulary:\n",
    "            return 'MISC'\n",
    "        tag_freq = self.frequencies[word.lower()]\n",
    "        tag_freq = list(sorted(tag_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "        return tag_freq[0][0]\n",
    "\n",
    "def baseline_tag_sentence(model, sentence):\n",
    "    tags = []\n",
    "    for word in sentence:\n",
    "        tags.append(model.assign_tag(word))\n",
    "    return tags\n",
    "\n",
    "baseline_model = BaselineModel(corpus, tagset)\n",
    "baseline = Tagger(baseline_model, baseline_tag_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing del test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_set(tagger, test_set, verbose=False):\n",
    "    model_outputs, target_outputs = [], []\n",
    "    for i, sentence in enumerate(test_set):\n",
    "        sent, target_output = get_sent_and_tags(sentence)\n",
    "        target_outputs.append(target_output)\n",
    "        model_output = tagger.tag_sentence(sent)\n",
    "        model_outputs.append(model_output)\n",
    "        if verbose and i%1000 == 0:\n",
    "            print(f'Progress {i}/{len(test_set)}')\n",
    "    return model_outputs, target_outputs\n",
    "\n",
    "def get_sent_and_tags(sentence):\n",
    "    sent, tags = '', []\n",
    "    for token in sentence:\n",
    "        if token[0] not in [',', '.', '-', ':', '\\'', '(', ')']:\n",
    "            sent += token[0] + \" \"\n",
    "            tags.append(token[1])\n",
    "    return sent[:-1], tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model_outputs, target_outputs):\n",
    "    score = 0\n",
    "    total = 0\n",
    "    for i in range(len(model_outputs)):\n",
    "        for j in range(len(model_outputs[i])):\n",
    "            if target_outputs[i][j] == 'O':\n",
    "                continue\n",
    "            total += 1\n",
    "            if model_outputs[i][j] == target_outputs[i][j]:\n",
    "                score += 1\n",
    "    return score/total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision e recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(tagset, model_outputs, target_outputs):\n",
    "    true_positives = dict((tag,0) for tag in tagset)\n",
    "    false_positives = dict((tag,0) for tag in tagset)\n",
    "    false_negatives = dict((tag,0) for tag in tagset)\n",
    "    for i in range(len(model_outputs)):\n",
    "        for j in range(len(model_outputs[i])):\n",
    "            for tag in tagset:\n",
    "                if model_outputs[i][j] != tag and target_outputs[i][j] != tag:\n",
    "                    continue\n",
    "                if model_outputs[i][j] == target_outputs[i][j]:\n",
    "                    true_positives[tag] += 1\n",
    "                elif model_outputs[i][j] == tag:\n",
    "                    false_positives[tag] += 1\n",
    "                else:\n",
    "                    false_negatives[tag] += 1\n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(true_positives, false_positives):\n",
    "    precisions = dict()\n",
    "    for tag in true_positives:\n",
    "        if true_positives[tag] == 0:\n",
    "            precisions[tag] = 0\n",
    "            continue\n",
    "        precisions[tag] = true_positives[tag] / (true_positives[tag] + false_positives[tag])\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(true_positives, false_negatives):\n",
    "    recalls = dict()\n",
    "    for tag in true_positives:\n",
    "        if true_positives[tag] == 0:\n",
    "            recalls[tag] = 0\n",
    "            continue\n",
    "        recalls[tag] = true_positives[tag] / (true_positives[tag] + false_negatives[tag])\n",
    "    return recalls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confronto con Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tagger(tagger, test_set):\n",
    "    model_outputs, target_outputs = process_test_set(tagger, test_set)\n",
    "    accuracy = compute_accuracy(model_outputs, target_outputs)\n",
    "    true_positives, false_positives, false_negatives = compute_statistics(tagger.tagset, model_outputs, target_outputs)\n",
    "    precision = compute_precision(true_positives, false_positives)\n",
    "    recall = compute_recall(true_positives, false_negatives)\n",
    "    print(f'---- Evaluating model {str(tagger.model.__class__.__name__)} ----')\n",
    "    print(f'Model accuracy on entities: {accuracy}')\n",
    "    print(f'Model precision per tag: {precision}')\n",
    "    print(f'Model recall per tag: {recall}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_corpus(f'data/{lang}/test.conllu')\n",
    "N = len(test_set)\n",
    "# N = 10\n",
    "\n",
    "for tagger in [hmm_viterbi, baseline]:\n",
    "    evaluate_tagger(tagger, test_set[:N])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Harry           Potter          's              true            home            is              Hogwarts        Castle          .               \n",
      "O               O               O               O               O               O               O               O               O               \n",
      "PER             MISC            O               O               O               O               MISC            LOC             O               \n",
      "PER             PER             O               O               O               O               LOC             LOC             O               \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Harry           told            her             about           their           meeting         at              Diagon          Alley           .               \n",
      "O               O               O               O               O               O               O               O               O               O               \n",
      "PER             O               O               O               O               O               O               MISC            LOC             O               \n",
      "PER             O               O               O               O               O               O               LOC             LOC             O               \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mr.             Dursley         was             director        of              a               company         named           Grunnings       that            manufactured    drills          .               \n",
      "O               O               O               O               O               O               O               O               O               O               O               O               O               \n",
      "MISC            LOC             O               O               O               O               O               O               MISC            O               O               O               O               \n",
      "PER             PER             O               O               O               O               O               O               ORG             O               O               O               O               \n"
     ]
    }
   ],
   "source": [
    "sentences = {\n",
    "    'it': [\n",
    "        'La vera casa di Harry Potter è il Castello di Hogwarts .',\n",
    "        'Harry le raccontò del loro incontro a Diagon Alley .',\n",
    "        'Mr Dursley era direttore di una ditta di nome Grunnings , che fabbricava trapani .'\n",
    "    ], 'en': [\n",
    "        'Harry Potter \\'s true home is Hogwarts Castle .',\n",
    "        'Harry told her about their meeting at Diagon Alley .',\n",
    "        'Mr. Dursley was director of a company named Grunnings that manufactured drills .'\n",
    "    ]\n",
    "}\n",
    "\n",
    "correct_tags = {\n",
    "    'it': [\n",
    "        ['O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'LOC', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O'],\n",
    "    ], 'en': [\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O'],\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i, sentence in enumerate(sentences[lang]):\n",
    "    print('-'*225)\n",
    "    header = sentence.split()\n",
    "    row1 = hmm_viterbi.tag_sentence(sentence)\n",
    "    row2 = baseline.tag_sentence(sentence)\n",
    "    row3 = correct_tags[lang][i]\n",
    "    rows = [header, row1, row2, row3]\n",
    "    print('\\n'.join([''.join(['{:16}'.format(x) for x in r]) for r in rows]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

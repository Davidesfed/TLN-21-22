{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Tagging con Viterbi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentazione si trova al seguente link https://github.com/Davidesfed/TLN-21-22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni accessorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(number):\n",
    "    if number == 0:\n",
    "        number += 1e-15\n",
    "    return math.log(number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(path):\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        return parse_conllu(f.readlines())\n",
    "\n",
    "def parse_conllu(lines):\n",
    "    result = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        if len(line) <= 1:\n",
    "            result.append(sentence.copy())\n",
    "            sentence = []\n",
    "        else:\n",
    "            token = parse_conllu_token(line)\n",
    "            sentence.append(token)\n",
    "    return result\n",
    "\n",
    "def parse_conllu_token(line):\n",
    "    line = line.strip('\\n').split('\\t')\n",
    "    tag = line[2]\n",
    "    if tag != 'O':\n",
    "        tag = tag[2:]\n",
    "    return (line[1], tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagger():\n",
    "    # Simple interface that will only be used to evaluate the two models\n",
    "    def __init__(self, model, algorithm):\n",
    "        self.model = model\n",
    "        self.algorithm = algorithm\n",
    "        self.tagset = model.tagset\n",
    "\n",
    "    def tag_sentence(self, sentence):\n",
    "        if sentence.__class__ == str:\n",
    "            sentence = sentence.lower().split()\n",
    "        return self.algorithm(self.model, sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    def __init__(self, corpus, tagset):\n",
    "        self.tagset = tagset\n",
    "        self.vocabulary = self.build_vocabulary(corpus)\n",
    "        self.start_prob = self.compute_start_prob(corpus)\n",
    "        self.end_prob = self.compute_end_prob(corpus)\n",
    "        self.transition_prob = self.compute_transition_prob(corpus)\n",
    "        self.emission_prob = self.compute_emission_prob(corpus)\n",
    "        self.smoothing_strategy = 'always_o'\n",
    "    \n",
    "    # Building methods\n",
    "    def build_vocabulary(self, corpus):\n",
    "        vocabulary = set()\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                vocabulary.add(token[0].lower())\n",
    "        return list(vocabulary)\n",
    "\n",
    "    def compute_start_prob(self, corpus):\n",
    "        # The start probabilities are calculated as frequencies\n",
    "        count_tag = dict((tag,0) for tag in self.tagset)\n",
    "        for sent in corpus:\n",
    "            tag = sent[0][1]\n",
    "            count_tag[tag] += 1\n",
    "        n = len(corpus)\n",
    "        return dict((tag,count/n) for tag,count in count_tag.items())\n",
    "\n",
    "    def compute_transition_prob(self, corpus):\n",
    "        # The transition probabilities are calculated as frequencies\n",
    "\n",
    "        # Inizialization\n",
    "        count_tag = dict(((tag1, tag2),0) for tag1 in self.tagset for tag2 in self.tagset)\n",
    "        total = dict((tag, 0) for tag in self.tagset)\n",
    "    \n",
    "        # Count of all the possible couples of tags and totals\n",
    "        for sent in corpus:\n",
    "            for i in range(len(sent)-1):\n",
    "                tag1 = sent[i][1]\n",
    "                total[tag1] += 1\n",
    "                tag2 = sent[i+1][1]\n",
    "                count_tag[(tag1, tag2)] += 1\n",
    "\n",
    "        # Division of count per totals, in order to obtain the frequency for each couple\n",
    "        for tag1 in self.tagset:\n",
    "            for tag2 in self.tagset:\n",
    "                count_tag[(tag1,tag2)] = count_tag[(tag1,tag2)]/total[tag1]\n",
    "        return count_tag\n",
    "\n",
    "    def compute_end_prob(self, corpus):\n",
    "        # The end probabilities are calculated as frequencies.\n",
    "        count_tag = dict((tag,0) for tag in self.tagset)\n",
    "        for sent in corpus:\n",
    "            # Punctuation is excluded from the count, so we have to retrieve the last non-punctuation tag\n",
    "            tag = self._get_last_tag(sent)\n",
    "            count_tag[tag] += 1\n",
    "        n = len(corpus)\n",
    "        return dict((tag, count/n) for tag,count in count_tag.items())\n",
    "\n",
    "    def _get_last_tag(self, sent):\n",
    "        # Returns the tag of the last non-punctuation token\n",
    "        for i, token in enumerate(reversed(sent)):\n",
    "            if token[0] not in [',', '.', '-', ':', '\\'', '(', ')', '\"']:\n",
    "                return token[1]\n",
    "\n",
    "    def compute_emission_prob(self, corpus):\n",
    "        # The emission probabilities are calculated as frequencies\n",
    "\n",
    "        # Inizialization\n",
    "        count_dict = dict(((word, tag),0) for word in self.vocabulary for tag in self.tagset)\n",
    "        total = dict((tag, 0) for tag in self.tagset)\n",
    "\n",
    "        # Count the number of occurrences and totals\n",
    "        for sent in corpus:\n",
    "            for word, tag in sent:\n",
    "                count_dict[(word.lower(), tag)] += 1\n",
    "                total[tag] += 1\n",
    "\n",
    "        # Divide the n. of occurrences for the total, contained in \n",
    "        for word, tag in count_dict:\n",
    "            count_dict[(word,tag)] = count_dict[(word,tag)]/total[tag]\n",
    "        return count_dict\n",
    "\n",
    "    # Getters and setters\n",
    "    def get_start_prob(self, tag):\n",
    "        return self.start_prob[tag]\n",
    "\n",
    "    def get_transition_prob(self, tag1, tag2):\n",
    "        return self.transition_prob[(tag1, tag2)]\n",
    "\n",
    "    def get_end_prob(self, tag):\n",
    "        return self.end_prob[tag]\n",
    "\n",
    "    def get_emission_prob(self, word, tag):\n",
    "        # Getters that behaves differently depending on the selected smoothing strategy\n",
    "        if word.lower() in self.vocabulary:\n",
    "            return self.emission_prob[(word.lower(),tag)]\n",
    "        if self.smoothing_strategy == 'always_o':\n",
    "            return 1.0 if tag == 'O' else 0.0\n",
    "        if self.smoothing_strategy == 'misc_or_o':\n",
    "            return 0.5 if tag in ['MISC', 'O'] else 0.0\n",
    "        if self.smoothing_strategy == 'uniform':\n",
    "            return 1/len(self.tagset)\n",
    "\n",
    "    def set_smoothing_strategy(self, strategy):\n",
    "        if strategy.lower() in ['always_o', 'misc_or_o', 'uniform']:\n",
    "            self.smoothing_strategy = strategy.lower()\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect smoothing strategy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(model, sentence):\n",
    "    # We will not work with probabilities but with log probabilities, hence the -inf in place of 0 and + in place of *\n",
    "    viterbi_matrix, backpointer = inizialitazion_step(model, sentence)\n",
    "    result = 0\n",
    "    for t in range(1,len(sentence)):\n",
    "        for i in range(len(model.tagset)):\n",
    "            viterbi_matrix[i][t], backpointer[i][t] = compute_max(model, viterbi_matrix, sentence[t], t, i)\n",
    "    viterbi_matrix[-1][-1], backpointer[-1][-1] = termination_step(model, viterbi_matrix)\n",
    "    result = backtrace(backpointer, model.tagset)\n",
    "    return result\n",
    "\n",
    "def inizialitazion_step(model, sentence):\n",
    "    tagset = model.tagset\n",
    "    viterbi_matrix = [[-math.inf for _ in range(len(sentence))] for _ in range(len(tagset)+1)]\n",
    "    backpointer = [[-1 for _ in range(len(sentence))] for _ in range(len(tagset)+1)]\n",
    "    for i, tag in enumerate(tagset):\n",
    "        start_prob = log(model.get_start_prob(tag))\n",
    "        emission_prob = log(model.get_emission_prob(sentence[0], tag))\n",
    "        viterbi_matrix[i][0] = start_prob + emission_prob\n",
    "        backpointer[i][0] = 0\n",
    "    return viterbi_matrix, backpointer\n",
    "\n",
    "def compute_max(model, viterbi_matrix, word, t, i):\n",
    "    tagset = model.tagset\n",
    "    max_prob =  viterbi_matrix[0][t-1] + log(model.get_transition_prob(tagset[0], tagset[i])) \n",
    "    max_tag = tagset[0]\n",
    "    for j in range(1, len(tagset)):\n",
    "        transition_prob = log(model.get_transition_prob(tagset[j], tagset[i]))\n",
    "        log_prob = viterbi_matrix[j][t-1] + transition_prob\n",
    "        if log_prob > max_prob:\n",
    "            max_prob = log_prob\n",
    "            max_tag = tagset[j]\n",
    "    emission_prob = log(model.get_emission_prob(word, tagset[i]))\n",
    "    return max_prob + emission_prob, max_tag\n",
    "\n",
    "def termination_step(model, viterbi_matrix):\n",
    "    tagset = model.tagset\n",
    "    max_prob = viterbi_matrix[0][-1] + log(model.get_end_prob(tagset[0]))\n",
    "    max_tag = tagset[0]\n",
    "    for j in range(1,len(tagset)):\n",
    "        end_prob = model.get_end_prob(tagset[j])\n",
    "        log_prob = viterbi_matrix[j][-1] + log(end_prob)\n",
    "        if log_prob > max_prob:\n",
    "            max_prob = log_prob\n",
    "            max_tag = tagset[j]\n",
    "    return max_prob, max_tag\n",
    "\n",
    "def backtrace(backpointer, tagset):\n",
    "    tags = [backpointer[-1][-1]]\n",
    "    for t in range(len(backpointer[0])-1, 0, -1):\n",
    "        tag = tags[-1]\n",
    "        tag_idx = tagset.index(tag)\n",
    "        tags.append(backpointer[tag_idx][t])\n",
    "    return list(reversed(tags))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "    def __init__(self, corpus, tagset):\n",
    "        self.tagset = tagset\n",
    "        self.vocabulary = self.build_vocabulary(corpus)\n",
    "        self.frequencies = self.compute_frequencies(corpus)\n",
    "\n",
    "    def build_vocabulary(self, corpus):\n",
    "        vocabulary = set()\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                vocabulary.add(token[0].lower())\n",
    "        return list(vocabulary)\n",
    "    \n",
    "    def compute_frequencies(self, corpus):\n",
    "        # The values calculated are not tecnically frequencies, but occurrences. Since we only care about the max value it does not matter.\n",
    "        word_dict = dict((tag, 0) for tag in self.tagset)\n",
    "        freq_dict = dict((word, word_dict.copy()) for word in self.vocabulary)\n",
    "        for sent in corpus:\n",
    "            for token in sent:\n",
    "                freq_dict[token[0].lower()][token[1]] += 1\n",
    "        return freq_dict\n",
    "    \n",
    "    def assign_tag(self, word):\n",
    "        if word.lower() not in self.vocabulary:\n",
    "            return 'MISC'\n",
    "        tag_freq = self.frequencies[word.lower()]\n",
    "        tag_freq = list(sorted(tag_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "        return tag_freq[0][0]\n",
    "\n",
    "def baseline_tag_sentence(model, sentence):\n",
    "    tags = []\n",
    "    for word in sentence:\n",
    "        tags.append(model.assign_tag(word))\n",
    "    return tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing del test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_set(tagger, test_set):\n",
    "    model_outputs, target_outputs = [], []\n",
    "    for sentence in test_set:\n",
    "        sent, target_output = get_sent_and_tags(sentence)\n",
    "        model_output = tagger.tag_sentence(sent)\n",
    "        target_outputs.append(target_output)\n",
    "        model_outputs.append(model_output)\n",
    "    return model_outputs, target_outputs\n",
    "\n",
    "def get_sent_and_tags(sentence):\n",
    "    sent, tags = [], []\n",
    "    for token in sentence:\n",
    "        sent.append(token[0].lower())\n",
    "        tags.append(token[1])\n",
    "    return sent, tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model_outputs, target_outputs):\n",
    "    score = 0\n",
    "    total = 0\n",
    "    for i in range(len(model_outputs)):\n",
    "        for j in range(len(model_outputs[i])):\n",
    "            total += 1\n",
    "            if model_outputs[i][j] == target_outputs[i][j]:\n",
    "                score += 1\n",
    "    return round(score/total, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision e recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(tagset, model_outputs, target_outputs):\n",
    "    true_positives = dict((tag,0) for tag in tagset)\n",
    "    false_positives = dict((tag,0) for tag in tagset)\n",
    "    false_negatives = dict((tag,0) for tag in tagset)\n",
    "    for i in range(len(model_outputs)):\n",
    "        for j in range(len(model_outputs[i])):\n",
    "            for tag in tagset:\n",
    "                if model_outputs[i][j] != tag and target_outputs[i][j] != tag:\n",
    "                    continue\n",
    "                if model_outputs[i][j] == target_outputs[i][j]:\n",
    "                    true_positives[tag] += 1\n",
    "                elif model_outputs[i][j] == tag:\n",
    "                    false_positives[tag] += 1\n",
    "                else:\n",
    "                    false_negatives[tag] += 1\n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(true_positives, false_positives):\n",
    "    precisions = dict()\n",
    "    for tag in true_positives:\n",
    "        if true_positives[tag] == 0:\n",
    "            precisions[tag] = 0\n",
    "            continue\n",
    "        precisions[tag] = round(true_positives[tag] / (true_positives[tag] + false_positives[tag]), 4)\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(true_positives, false_negatives):\n",
    "    recalls = dict()\n",
    "    for tag in true_positives:\n",
    "        if true_positives[tag] == 0:\n",
    "            recalls[tag] = 0\n",
    "            continue\n",
    "        recalls[tag] = round(true_positives[tag] / (true_positives[tag] + false_negatives[tag]), 4)\n",
    "    return recalls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confronto tra i modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tagger(tagger, test_set):\n",
    "    print(f'---- Evaluating model {str(tagger.algorithm.__name__)} ----')\n",
    "    start_time = time.time()\n",
    "    model_outputs, target_outputs = process_test_set(tagger, test_set)\n",
    "    end_time = time.time()\n",
    "    print(f'Evaluation of {len(test_set)} sentences took {int(end_time-start_time)} seconds')\n",
    "    accuracy = compute_accuracy(model_outputs, target_outputs)\n",
    "    true_positives, false_positives, false_negatives = compute_statistics(tagger.tagset, model_outputs, target_outputs)\n",
    "    precision = compute_precision(true_positives, false_positives)\n",
    "    recall = compute_recall(true_positives, false_negatives)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "    print(f'Model precision per tag: {precision}')\n",
    "    print(f'Model recall per tag: {recall}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating taggers for language: en\n",
      "---- Evaluating model viterbi ----\n"
     ]
    }
   ],
   "source": [
    "languages = ['en', 'it']\n",
    "tagset = ['O', 'ORG', 'LOC', 'PER', 'MISC']\n",
    "\n",
    "for lang in languages:\n",
    "    corpus = get_corpus(f'data/{lang}/train.conllu')\n",
    "\n",
    "    hmm = HiddenMarkovModel(corpus, tagset)\n",
    "    my_viterbi = Tagger(hmm, viterbi)\n",
    "\n",
    "    baseline_model = BaselineModel(corpus, tagset)\n",
    "    baseline = Tagger(baseline_model, baseline_tag_sentence)\n",
    "\n",
    "    test_set = get_corpus(f'data/{lang}/test.conllu')\n",
    "    N = len(test_set)\n",
    "    # N = 20\n",
    "\n",
    "    print(f\"Evaluating taggers for language: {lang}\")\n",
    "    for tagger in [my_viterbi, baseline]:\n",
    "        evaluate_tagger(tagger, test_set[:N])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                Harry           Potter          '               s               true            home            is              Hogwarts        Castle          .               \n",
      "Viterbi         PER             PER             O               O               O               O               O               MISC            MISC            O               \n",
      "Baseline        PER             MISC            O               O               O               O               O               MISC            LOC             O               \n",
      "Target          PER             PER             O               O               O               O               O               LOC             LOC             O               \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                Harry           told            her             about           their           meeting         at              Diagon          Alley           .               \n",
      "Viterbi         PER             O               O               O               O               O               O               O               LOC             O               \n",
      "Baseline        PER             O               O               O               O               O               O               MISC            LOC             O               \n",
      "Target          PER             O               O               O               O               O               O               LOC             LOC             O               \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                Mr.             Dursley         was             director        of              a               company         named           Grunnings       that            manufactured    drills          .               \n",
      "Viterbi         O               LOC             O               O               O               O               O               O               O               O               O               O               O               \n",
      "Baseline        MISC            LOC             O               O               O               O               O               O               MISC            O               O               O               O               \n",
      "Target          PER             PER             O               O               O               O               O               O               ORG             O               O               O               O               \n"
     ]
    }
   ],
   "source": [
    "sentences = {\n",
    "    'it': [\n",
    "        'La vera casa di Harry Potter è il Castello di Hogwarts .',\n",
    "        'Harry le raccontò del loro incontro a Diagon Alley .',\n",
    "        'Mr Dursley era direttore di una ditta di nome Grunnings , che fabbricava trapani .'\n",
    "    ], 'en': [\n",
    "        'Harry Potter \\' s true home is Hogwarts Castle .',\n",
    "        'Harry told her about their meeting at Diagon Alley .',\n",
    "        'Mr. Dursley was director of a company named Grunnings that manufactured drills .'\n",
    "    ]\n",
    "}\n",
    "\n",
    "correct_tags = {\n",
    "    'it': [\n",
    "        ['O', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'LOC', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O'],\n",
    "    ], 'en': [\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O'],\n",
    "        ['PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O'],\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i, sentence in enumerate(sentences[lang]):\n",
    "    print('-'*225)\n",
    "    header = sentence.split()\n",
    "    row1 = my_viterbi.tag_sentence(sentence)\n",
    "    row2 = baseline.tag_sentence(sentence)\n",
    "    row3 = correct_tags[lang][i]\n",
    "    rows = [header, row1, row2, row3]\n",
    "    names = ['', 'Viterbi', 'Baseline', 'Target']\n",
    "    for i in range(len(rows)):\n",
    "        rows[i].insert(0,names[i])\n",
    "    print('\\n'.join([''.join(['{:16}'.format(x) for x in r]) for r in rows]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031491204956330055"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob_two_ne_near(path):\n",
    "    number = 0\n",
    "    total = 0\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)-1):\n",
    "            if 'B-' in lines[i]:\n",
    "                total += 1\n",
    "            if 'I-' in lines[i] and 'B-' in lines[i+1]:\n",
    "                number += 1\n",
    "    return number/total\n",
    "\n",
    "prob_two_ne_near('data/en/train.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "def trasposta(matrix):\n",
    "    res = []\n",
    "    for i in range(len(matrix[0])):\n",
    "        new_col = []\n",
    "        for row in matrix:\n",
    "            new_col.append(row[i])\n",
    "        res.append(new_col.copy())\n",
    "    return res\n",
    "\n",
    "def print_table(input_matrix):\n",
    "    V = trasposta(input_matrix)\n",
    "    yield \" \".join((\"%12d\" % i) for i in range(len(V)))\n",
    "    for state in range(len(V[0])):\n",
    "        yield \"%.7s: \" % state + \" \".join(\"%.7s\" % (\"%f\" % v[state]) for v in V)\n",
    "\n",
    "sentence=\"on this occasion he failed to gain the support of the South Wales Miners ' Federation and had to stand down .\"\n",
    "tagset = viterbi(hmm, sentence.split())\n",
    "print(tagset)\n",
    "# for line in print_table(b):\n",
    "#     print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

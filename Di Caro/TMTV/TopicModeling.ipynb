{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint\n",
    "from gensim.parsing.preprocessing import preprocess_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documents(path):\n",
    "    file = open(path, encoding=\"utf8\")\n",
    "    train_set = csv.reader(file)\n",
    "\n",
    "    header = next(train_set)\n",
    "    documents = []\n",
    "    tags = []\n",
    "    for doc in train_set:\n",
    "        documents.append(doc[1])\n",
    "        tags.append(doc[2:])\n",
    "    file.close()\n",
    "\n",
    "    return header, documents, tags\n",
    "\n",
    "PATH = 'dataset/Train.csv'\n",
    "header, documents, tags = get_documents(PATH)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_documents = preprocess_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 5), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 3), (24, 1), (25, 5), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 3), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1), (47, 4), (48, 1), (49, 1), (50, 3), (51, 1), (52, 1), (53, 1), (54, 11), (55, 1), (56, 6), (57, 1), (58, 1), (59, 1), (60, 2), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 4), (70, 1), (71, 1), (72, 2), (73, 3), (74, 1), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 3), (85, 1), (86, 1), (87, 1), (88, 1), (89, 2), (90, 1), (91, 1), (92, 2), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 3), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 6), (110, 5), (111, 1), (112, 1), (113, 1), (114, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = Dictionary(preprocessed_documents)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(doc) for doc in preprocessed_documents]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus,\n",
    "                    id2word=id2word,\n",
    "                    num_topics=len(header[1:]), \n",
    "                    random_state=100,\n",
    "                    update_every=1,\n",
    "                    chunksize=100,\n",
    "                    passes=10,\n",
    "                    alpha='auto',\n",
    "                    per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5,\n",
      "  '0.324*\"group\" + 0.217*\"distanc\" + 0.087*\"formula\" + 0.084*\"constrain\" + '\n",
      "  '0.036*\"tau\" + 0.029*\"round\" + 0.029*\"hilbert\" + 0.004*\"gross\" + '\n",
      "  '0.003*\"certain\" + 0.000*\"atv\"'),\n",
      " (12,\n",
      "  '0.311*\"graph\" + 0.137*\"node\" + 0.087*\"maxim\" + 0.082*\"updat\" + '\n",
      "  '0.039*\"vertic\" + 0.034*\"graphic\" + 0.031*\"structur\" + 0.030*\"market\" + '\n",
      "  '0.027*\"deploi\" + 0.025*\"proxim\"'),\n",
      " (21,\n",
      "  '0.142*\"devic\" + 0.125*\"materi\" + 0.120*\"boundari\" + 0.085*\"polar\" + '\n",
      "  '0.066*\"grid\" + 0.058*\"concentr\" + 0.034*\"cooper\" + 0.032*\"tunnel\" + '\n",
      "  '0.024*\"contract\" + 0.021*\"defect\"'),\n",
      " (4,\n",
      "  '0.143*\"tool\" + 0.141*\"popul\" + 0.100*\"stage\" + 0.076*\"causal\" + '\n",
      "  '0.065*\"mobil\" + 0.042*\"littl\" + 0.030*\"custom\" + 0.029*\"ask\" + 0.027*\"sky\" '\n",
      "  '+ 0.026*\"mitig\"'),\n",
      " (20,\n",
      "  '0.212*\"commun\" + 0.186*\"question\" + 0.102*\"pair\" + 0.081*\"relationship\" + '\n",
      "  '0.080*\"answer\" + 0.071*\"examin\" + 0.032*\"distinguish\" + 0.031*\"author\" + '\n",
      "  '0.027*\"highest\" + 0.013*\"median\"'),\n",
      " (18,\n",
      "  '0.108*\"relev\" + 0.092*\"perturb\" + 0.090*\"matter\" + 0.077*\"univers\" + '\n",
      "  '0.077*\"heurist\" + 0.074*\"dark\" + 0.050*\"fluid\" + 0.043*\"cosmolog\" + '\n",
      "  '0.041*\"turbul\" + 0.037*\"scalar\"'),\n",
      " (26,\n",
      "  '0.100*\"mathbb\" + 0.072*\"lambda\" + 0.070*\"gamma\" + 0.054*\"mathcal\" + '\n",
      "  '0.047*\"satisfi\" + 0.042*\"frac\" + 0.035*\"delta\" + 0.031*\"let\" + '\n",
      "  '0.031*\"sigma\" + 0.029*\"beta\"'),\n",
      " (22,\n",
      "  '0.181*\"energi\" + 0.135*\"power\" + 0.077*\"spectrum\" + 0.058*\"background\" + '\n",
      "  '0.052*\"fraction\" + 0.052*\"law\" + 0.047*\"minimum\" + 0.025*\"outlier\" + '\n",
      "  '0.021*\"subgraph\" + 0.021*\"photon\"'),\n",
      " (15,\n",
      "  '0.154*\"convex\" + 0.153*\"converg\" + 0.137*\"gradient\" + 0.135*\"regular\" + '\n",
      "  '0.121*\"stochast\" + 0.045*\"rate\" + 0.040*\"composit\" + 0.028*\"act\" + '\n",
      "  '0.027*\"norm\" + 0.015*\"implicit\"'),\n",
      " (19,\n",
      "  '0.126*\"matrix\" + 0.124*\"metric\" + 0.084*\"project\" + 0.077*\"rank\" + '\n",
      "  '0.073*\"polynomi\" + 0.056*\"tensor\" + 0.053*\"plane\" + 0.052*\"restrict\" + '\n",
      "  '0.045*\"product\" + 0.040*\"decomposit\"'),\n",
      " (0,\n",
      "  '0.338*\"network\" + 0.123*\"neural\" + 0.104*\"deep\" + 0.069*\"train\" + '\n",
      "  '0.054*\"convolut\" + 0.050*\"end\" + 0.035*\"learn\" + 0.032*\"filter\" + '\n",
      "  '0.025*\"input\" + 0.021*\"baselin\"'),\n",
      " (6,\n",
      "  '0.167*\"learn\" + 0.091*\"robot\" + 0.053*\"task\" + 0.048*\"human\" + '\n",
      "  '0.037*\"action\" + 0.034*\"machin\" + 0.031*\"purpos\" + 0.028*\"tempor\" + '\n",
      "  '0.019*\"decis\" + 0.018*\"navig\"'),\n",
      " (10,\n",
      "  '0.461*\"model\" + 0.106*\"predict\" + 0.053*\"infer\" + 0.026*\"bayesian\" + '\n",
      "  '0.026*\"prior\" + 0.020*\"latent\" + 0.015*\"likelihood\" + 0.015*\"entropi\" + '\n",
      "  '0.015*\"uncertainti\" + 0.014*\"variat\"'),\n",
      " (24,\n",
      "  '0.068*\"mode\" + 0.055*\"layer\" + 0.038*\"degre\" + 0.036*\"mechan\" + '\n",
      "  '0.034*\"metal\" + 0.034*\"correl\" + 0.025*\"free\" + 0.021*\"invari\" + '\n",
      "  '0.021*\"zero\" + 0.020*\"abl\"'),\n",
      " (13,\n",
      "  '0.042*\"method\" + 0.037*\"depth\" + 0.032*\"imag\" + 0.029*\"reconstruct\" + '\n",
      "  '0.026*\"featur\" + 0.026*\"propos\" + 0.026*\"dataset\" + 0.022*\"perform\" + '\n",
      "  '0.021*\"object\" + 0.020*\"learn\"'),\n",
      " (28,\n",
      "  '0.082*\"problem\" + 0.070*\"algorithm\" + 0.048*\"optim\" + 0.039*\"method\" + '\n",
      "  '0.036*\"propos\" + 0.028*\"comput\" + 0.025*\"time\" + 0.025*\"effici\" + '\n",
      "  '0.015*\"idea\" + 0.015*\"achiev\"'),\n",
      " (1,\n",
      "  '0.055*\"gener\" + 0.055*\"insid\" + 0.054*\"function\" + 0.034*\"consid\" + '\n",
      "  '0.029*\"space\" + 0.026*\"point\" + 0.024*\"dimension\" + 0.020*\"case\" + '\n",
      "  '0.020*\"non\" + 0.018*\"class\"'),\n",
      " (2,\n",
      "  '0.105*\"insid\" + 0.020*\"observ\" + 0.017*\"time\" + 0.017*\"scale\" + '\n",
      "  '0.015*\"dynam\" + 0.014*\"high\" + 0.012*\"measur\" + 0.012*\"structur\" + '\n",
      "  '0.012*\"studi\" + 0.012*\"larg\"'),\n",
      " (29,\n",
      "  '0.102*\"insid\" + 0.027*\"consid\" + 0.025*\"data\" + 0.020*\"system\" + '\n",
      "  '0.020*\"process\" + 0.017*\"inform\" + 0.017*\"base\" + 0.016*\"work\" + '\n",
      "  '0.016*\"differ\" + 0.014*\"us\"'),\n",
      " (7,\n",
      "  '0.099*\"consid\" + 0.053*\"insid\" + 0.022*\"result\" + 0.018*\"approxim\" + '\n",
      "  '0.017*\"method\" + 0.015*\"distribut\" + 0.014*\"number\" + 0.013*\"help\" + '\n",
      "  '0.013*\"paramet\" + 0.013*\"sampl\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f51c5fe9e9a58efa1043b1548cfcb156c8f39c9e60365a17bc19defd3d30b528"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

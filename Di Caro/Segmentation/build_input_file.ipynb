{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation - Build input file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.test.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabili Globali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link delle pagine di wikipedia che vogliamo estrarre\n",
    "WIKI_PAGES = ['https://en.wikipedia.org/wiki/Film', 'https://en.wikipedia.org/wiki/Therapy', 'https://en.wikipedia.org/wiki/Napoleon_Bonaparte']\n",
    "\n",
    "# Nomi dei file in cui vogliamo salvare ogni pagina\n",
    "FILE_NAMES = ['film', 'therapy', 'napoleon']\n",
    "\n",
    "# Seed per riproducibilità\n",
    "random.seed(2.4)\n",
    "\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "\n",
    "# Iperparametri\n",
    "FRAGMENTS_LENGHT = 5 # Numero di paragrafi per argomento che inseriremo nel file di input all'algoritmo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione del file di input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Da Wikipedia al file page_[nome].txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per estrarre i dati dalle pagine di wikipedia le scarichiamo come testo integrale HTML e utilizziamo BeautifulSoup per navigare l'albero dei tag HTML ed estrarre il testo contenuto in essi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of Wiki Page \"https://en.wikipedia.org/wiki/Film\" saved in file \"page_film\"\n",
      "Content of Wiki Page \"https://en.wikipedia.org/wiki/Therapy\" saved in file \"page_therapy\"\n",
      "Content of Wiki Page \"https://en.wikipedia.org/wiki/Napoleon_Bonaparte\" saved in file \"page_napoleon\"\n"
     ]
    }
   ],
   "source": [
    "def save_to_file(wiki_pages, file_names):\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        with open(f'resources/building_res/page_{file_name}.txt', 'w', encoding='utf-8') as f:\n",
    "            data = retrieve_wiki_page(wiki_pages[i])\n",
    "            f.write(data)\n",
    "            print(f'Content of Wiki Page \"{wiki_pages[i]}\" saved in file \"page_{file_name}\"')\n",
    "\n",
    "def retrieve_wiki_page(url):\n",
    "    response = requests.get(url)\n",
    "    text = to_plaintext(response.text)\n",
    "    text = re.sub(r'\\[[0-9]*\\]', '', text)\n",
    "    text = re.sub(r'\\[[a-z]*\\]', '', text)\n",
    "    return text\n",
    "\n",
    "def to_plaintext(html_text):\n",
    "    soup = BeautifulSoup(html_text, features=\"lxml\")\n",
    "    extracted_blocks = _extract_blocks(soup.body)\n",
    "    extracted_blocks_texts = [block.get_text().strip() for block in extracted_blocks]\n",
    "    return \"\\n\".join(extracted_blocks_texts)\n",
    "\n",
    "def _extract_blocks(parent_tag):\n",
    "    blocks = [\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"blockquote\"] # Nomi dei tag html da cui vogliamo estrarre testo\n",
    "    extracted_blocks = []\n",
    "    for tag in parent_tag:\n",
    "        if tag.name in blocks:\n",
    "            extracted_blocks.append(tag)\n",
    "            continue\n",
    "        if isinstance(tag, Tag):\n",
    "            if len(tag.contents) > 0:\n",
    "                inner_blocks = _extract_blocks(tag)\n",
    "                if len(inner_blocks) > 0:\n",
    "                    extracted_blocks.extend(inner_blocks)\n",
    "    return extracted_blocks\n",
    "\n",
    "save_to_file(WIKI_PAGES, FILE_NAMES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Da page_[nome].txt a data_[nome].txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella prossima funzione partendo dal file \"page\" costruiamo un file che conterrà i dati da preprocessare filtrando i titoli delle sezioni e le sezioni troppo corte per essere rilevanti. Rimuoviamo inoltre i \"...\", caratteri molto comuni nelle pagine di Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file named \"data_film.txt\" created.\n",
      "Data file named \"data_therapy.txt\" created.\n",
      "Data file named \"data_napoleon.txt\" created.\n"
     ]
    }
   ],
   "source": [
    "def create_data_file(file_names):\n",
    "    res = []\n",
    "    for file_name in file_names:\n",
    "        with open(f'resources/building_res/page_{file_name}.txt', 'r', encoding='utf-8') as f:\n",
    "            data = f.readlines()\n",
    "            data = list(filter(lambda x: len(x)>100, data))\n",
    "            data = list(map(lambda x: x.replace('...', '.'), data))\n",
    "            res.extend(data)\n",
    "        \n",
    "        with open(f'resources/building_res/data_{file_name}.txt', 'w',  encoding='utf-8') as f:\n",
    "            for item in data:\n",
    "                f.write(item)\n",
    "        \n",
    "        print(f'Data file named \"data_{file_name}.txt\" created.')\n",
    "\n",
    "create_data_file(FILE_NAMES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione del file di input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo quindi il documento di input all'algoritmo, prendendo `fragments_length` paragrafi per ogni file `data_[nome].txt`. \n",
    "Nella costruzione del file di input salviamo anche le posizioni corrette dove inserire i tagli, variabile che utilizzeremo nella valutazione dell'algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input document: ['A preview performance refers to a showing of a film to a select audience, usually for the purposes of corporate promotions, before the public film premiere itself', 'Previews are sometimes used to judge audience reaction, which if unexpectedly negative, may result in recutting or even refilming certain sections based on the audience response', \"One example of a film that was changed after a negative response from the test screening is 1982's First Blood\", 'After the test audience responded very negatively to the death of protagonist John Rambo, a Vietnam veteran, at the end of the film, the company wrote and re-shot a new ending in which the character survives.', 'Trailers or previews are advertisements for films that will be shown in 1 to 3 months at a cinema', 'Back in the early days of cinema, with theaters that had only one or two screens, only certain trailers were shown for the films that were going to be shown there', \"Later, when theaters added more screens or new theaters were built with a lot of screens, all different trailers were shown even if they weren't going to play that film in that theater\", \"Film studios realized that the more trailers that were shown (even if it wasn't going to be shown in that particular theater) the more patrons would go to a different theater to see the film when it came out\", 'The term \"trailer\" comes from their having originally been shown at the end of a film program', 'That practice did not last long because patrons tended to leave the theater after the films ended, but the name has stuck', 'Trailers are now shown before the film (or the \"A film\" in a double feature program) begins', 'Film trailers are also common on DVDs and Blu-ray Discs, as well as on the Internet and mobile devices', 'Trailers are created to be engaging and interesting for viewers', 'As a result, in the Internet era, viewers often seek out trailers to watch them', 'Of the ten billion videos watched online annually in 2008, film trailers ranked third, after news and user-created videos', 'Teasers are a much shorter preview or advertisement that lasts only 10 to 30 seconds', 'Teasers are used to get patrons excited about a film coming out in the next six to twelve months', 'Teasers may be produced even before the film production is completed.', 'Films are cultural artifacts created by specific cultures, facilitating intercultural dialogue', 'It is considered to be an important art form that provides entertainment and historical value, often visually documenting a period of time', 'The visual basis of the medium gives it a universal power of communication, often stretched further through the use of dubbing or subtitles to translate the dialog into other languages', 'Just seeing a location in a film is linked to higher tourism to that location, demonstrating how powerful the suggestive nature of the medium can be.', 'Film is used for a range of goals, including education and propaganda due its ability to effectively intercultural dialogue', 'When the purpose is primarily educational, a film is called an \"educational film\"', 'Examples are recordings of academic lectures and experiments, or a film based on a classic novel', 'Film may be propaganda, in whole or in part, such as the films made by Leni Riefenstahl in Nazi Germany, US war film trailers during World War II, or artistic films made under Stalin by Sergei Eisenstein', 'They may also be works of political protest, as in the films of Andrzej Wajda, or more subtly, the films of Andrei Tarkovsky', 'The same film may be considered educational by some, and propaganda by others as the categorization of a film can be subjective.', 'At its core, the means to produce a film depend on the content the filmmaker wishes to show, and the apparatus for displaying it: the zoetrope merely requires a series of images on a strip of paper', \"Film production can, therefore, take as little as one person with a camera (or even without a camera, as in Stan Brakhage's 1963 film Mothlight), or thousands of actors, extras, and crew members for a live-action, feature-length epic.\", 'A therapy or medical treatment (often abbreviated tx, Tx, or Tx) is the attempted remediation of a health problem, usually following a medical diagnosis.', 'As a rule, each therapy has indications and contraindications', ' There are many different types of therapy', ' Not all therapies are effective', ' Many therapies can produce unwanted adverse effects.', 'Medical treatment and therapy are generally considered synonyms', ' However,  in the context of mental health, the term therapy may refer specifically to psychotherapy.', 'Before the creating of therapy as a formal procedure, people told stories to one another to inform and assist about the world', 'The term \"healing through words\" was used over 3,500 years ago in Greek and Egyptian writing', 'The term psychotherapy was invented in the 19th century, and psychoanalysis was founded by Sigmund Freud under a decade later.', 'The words care, therapy, treatment, and intervention overlap in a semantic field, and thus they can be synonymous depending on context', 'Moving rightward through that order, the connotative level of holism decreases and the level of specificity (to concrete instances) increases', \"Thus, in health care contexts (where its senses are always noncount), the word care tends to imply a broad idea of everything done to protect or improve someone's health (for example, as in the terms preventive care and primary care, which connote ongoing action), although it sometimes implies a narrower idea (for example, in the simplest cases of wound care or postanesthesia care, a few particular steps are sufficient, and the patient's interaction with that provider is soon finished)\", 'In contrast, the word intervention tends to be specific and concrete, and thus the word is often countable; for example, one instance of cardiac catheterization is one intervention performed, and coronary care (noncount) can require a series of interventions (count)', 'At the extreme, the piling on of such countable interventions amounts to interventionism, a flawed model of care lacking holistic circumspection—merely treating discrete problems (in billable increments) rather than maintaining health', 'Therapy and treatment, in the middle of the semantic field, can connote either the holism of care or the discreteness of intervention, with context conveying the intent in each use', 'Accordingly, they can be used in both noncount and count senses (for example, therapy for chronic kidney disease can involve several dialysis treatments per week).', \"Napoleon's family was of Italian origin\", 'His paternal ancestors, the Buonapartes, descended from a minor Tuscan noble family who emigrated to Corsica in the 16th century and his maternal ancestors, the Ramolinos, descended from a minor Genoese noble family', 'The Buonapartes were also the relatives, by marriage and by birth, of the Pietrasentas, Costas, Paraviccinis, and Bonellis, all Corsican families of the interior', 'His parents Carlo Maria di Buonaparte and Maria Letizia Ramolino maintained an ancestral home called \"Casa Buonaparte\" in Ajaccio', 'Napoleon was born there on 15 August 1769', 'He was the fourth child and third son of the family', 'He had an elder brother, Joseph, and younger siblings Lucien, Elisa, Louis, Pauline, Caroline, and Jérôme', 'Napoleon was baptised as a Catholic, under the name Napoleone', 'In his youth, his name was also spelled as Nabulione, Nabulio, Napolionne, and Napulione.', 'Napoleon was born one year after that the Republic of Genoa (former Italian state) ceded the region of Corsica to France', 'The state sold sovereign rights a year before his birth and the island was conquered by France during the year of his birth', 'It was formally incorporated as a province in 1770, after 500 years under Genoese rule and 14 years of independence', \"Napoleon's parents joined the Corsican resistance and fought against the French to maintain independence, even when Maria was pregnant with him\", \"His father Carlo was an attorney who had supported and actively collaborated with patriot Pasquale Paoli during the Corsican war of independence against France; after the Corsican defeat at Ponte Novu in 1769 and Paoli's exile in Britain, Carlo began working for the new French government and went on to be named representative of the island to the court of Louis XVI in 1777.\", \"The dominant influence of Napoleon's childhood was his mother, whose firm discipline restrained a rambunctious child\", 'Later in life, Napoleon stated, \"The future destiny of the child is always the work of the mother.\" Napoleon\\'s maternal grandmother had married into the Swiss Fesch family in her second marriage, and Napoleon\\'s uncle, the cardinal Joseph Fesch, would fulfill a role as protector of the Bonaparte family for some years', \"Napoleon's noble, moderately affluent background afforded him greater opportunities to study than were available to a typical Corsican of the time.\", 'When he turned 9 years old, he moved to the French mainland and enrolled at a religious school in Autun in January 1779', 'In May, he transferred with a scholarship to a military academy at Brienne-le-Château', \"In his youth he was an outspoken Corsican nationalist and supported the state's independence from France\", 'Like many Corsicans, Napoleon spoke and read Corsican (as his mother tongue) and Italian (as the official language of Corsica)', 'He began learning French in school at around age 10', 'Although he became fluent in French, he spoke with a distinctive Corsican accent and never learned how to spell correctly in French', 'Consequently, Napoleon was treated unfairly by his schoolmates', \"He was, however, not an isolated case, as it was estimated in 1790 that fewer than 3\\xa0million people, out of France's population of 28\\xa0million, were able to speak standard French, and those who could write it were even fewer.\", 'Napoleon was routinely bullied by his peers for his accent, birthplace, short stature, mannerisms and inability to speak French quickly', 'He became reserved and melancholy, applying himself to reading', 'An examiner observed that Napoleon \"has always been distinguished for his application in mathematics', 'He is fairly well acquainted with history and geography\\xa0', 'This boy would make an excellent sailor\".']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(paths):\n",
    "    paths = [f'resources/building_res/data_{file_name}.txt' for file_name in paths]\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            doc = list(map(lambda x: x.strip('\\n'), f.readlines()))\n",
    "            #doc = list(filter(lambda x: len(x)>0, doc))\n",
    "            res.append(doc)\n",
    "    return res\n",
    "\n",
    "def build_input_doc(documents, fragments_length):\n",
    "    data = []\n",
    "    correct_cuts = []\n",
    "    for doc in documents:\n",
    "        i = random.randint(0,len(doc)-fragments_length)\n",
    "        for sent in doc[i:i+fragments_length]:\n",
    "            data.extend(sent.split('. '))\n",
    "        correct_cuts.append(len(data))\n",
    "    return data, correct_cuts[:-1]\n",
    "\n",
    "documents = get_data(FILE_NAMES)\n",
    "input_data, correct_cuts = build_input_doc(documents, FRAGMENTS_LENGHT)\n",
    "print(f'Input document: {input_data}')\n",
    "len(input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvataggio su file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File correctly saved.\n"
     ]
    }
   ],
   "source": [
    "def save_to_file(path, input_data, correct_cuts):\n",
    "    with open(path, 'w', encoding='utf8') as f:\n",
    "        for sent in input_data:\n",
    "            if sent[-1] != '.':\n",
    "                sent = sent + '. '\n",
    "            f.write(sent)\n",
    "        f.write('\\n' + str(correct_cuts[0]) + ' ' + str(correct_cuts[1]))\n",
    "    print(\"File correctly saved.\")\n",
    "\n",
    "save_to_file('resources/input_data.txt', input_data, correct_cuts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione degli embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero del modello di gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individuazione parole più frequenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words: ['film', 'napoleon', 'trailer', 'care', 'therapy', 'corsican', 'shown', 'year', 'french']\n"
     ]
    }
   ],
   "source": [
    "def build_freq_dict(input_doc):\n",
    "    frequency_dict = {}\n",
    "    prep_input_doc = simple_preprocess(\" \".join(input_doc))\n",
    "    for word in prep_input_doc:\n",
    "        if word not in STOPWORDS:\n",
    "            if is_plural(word):\n",
    "                word = to_singular(word)\n",
    "            if word not in frequency_dict.keys():\n",
    "                frequency_dict[word] = 0\n",
    "            frequency_dict[word] += 1\n",
    "    return frequency_dict\n",
    "\n",
    "def is_plural(word):\n",
    "    return word[-1] == 's' or word[-2:] == 'es'\n",
    "\n",
    "def to_singular(word):\n",
    "    if word[-2:] == 'es':\n",
    "        return word[:-2]\n",
    "    if  word[-1] == 's':\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def get_most_frequent_words(frequency_dict, n_words):\n",
    "    freq_list = sorted(frequency_dict, key=frequency_dict.get, reverse=True)\n",
    "    return freq_list[:n_words]\n",
    "\n",
    "freq_dict = build_freq_dict(input_data)\n",
    "most_freq_words = get_most_frequent_words(freq_dict, 9)\n",
    "print(f'Most frequent words: {most_freq_words}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione file con embeddings delle parole più frequenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings correctly saved.\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(words):\n",
    "    embeddings = dict()\n",
    "    for word in words:\n",
    "        embeddings[word] = list(float(x) for x in word_embeddings_model[word])\n",
    "    return embeddings\n",
    "\n",
    "def save_embeddings(path, embeddings):\n",
    "    with open(path, 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(embeddings))\n",
    "    print(\"Embeddings correctly saved.\")\n",
    "\n",
    "embedding_path = 'resources/embeddings.json'\n",
    "embeddings = get_embeddings(most_freq_words)\n",
    "save_embeddings(embedding_path, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ghigliottina"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ipotesi fatte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esecuzione di questo esercizio sono state fatte una serie di ipotesi in modo da semplificarne la risoluzione. Tali ipotesi sono qui elencate:\n",
    "1) La lingua scelta è l'inglese.\n",
    "2) Ammettiamo che i legami tra le cinque parole date siano unicamente dati da modi di dire.\n",
    "3) Il sistema deve sempre restituire una parola in output. Se abbiamo due o più parole che potrebbero essere la parola in output con la medesima probabilità, ne scegliamo una casualmente. \n",
    "4) Come nel gioco originale, consideriamo che il singolare e il plurale di una parola siano due termini diversi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminologia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per chiarezza esplicativa, in questo notebook useremo:\n",
    "- __parola__: per indicare una delle cinque parole date in input al sistema, oppure la parola di output\n",
    "- __termini__: tutti i termini che vengono utilizzati durante la computazione per trovare quale tra essi quello più adatto ad essere la parola di output\n",
    "- __(nel codice) quote__: un modo di dire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risorse utilizzate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una conseguenza dell'ipotesi (2) è che per risolvere questo esercizio è sufficiente avere una raccolta di modi di dire, il file `common_saying.txt`. Essa è stata costruita a mano, prendendo circa 2500 modi di dire in inglese trovati nel Web e sistemandone uno per riga. Ciascuno di questi modi di dire non è stato sottoposto ad alcuna operazione di pulizia, e quindi potrebbe presentare caratteri quali le parentesi o il trattino.\n",
    "\n",
    "Un'altra risorsa che viene utilizzata è il file `words.txt`. Questo contiene, in ogni riga, una serie di cinque parole, che sono i diversi possibili input al sistema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path delle risorse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTES_PATH = 'resources/common_saying.txt'\n",
    "WORDS_PATH = 'resources/words.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di manipolazione dei dati"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semplice funzione che permette di rimuovere stopword e punteggiatura da un termine. Non utilizziamo la lemmatizzazione in quanto, per l'Ipotesi (4) vogliamo fare distizione tra singolari e plurali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_term(term):\n",
    "    delete_punctuation_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    term = term.lower()\n",
    "    if not term in stopwords.words():\n",
    "        no_punct_term = delete_punctuation_tokenizer.tokenize(term)\n",
    "        if len(no_punct_term) > 0:\n",
    "            return no_punct_term[0]\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipolazione dei modi di dire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viste le premesse, è necessario avere delle funzioni ad hoc che permettano una comoda manipolazione dei modi di dire. In particolare ci servirà una funzione per leggere i modi di dire dal file, e un'altra che permetta di togliere i caratteri speciali laddove serva. In ultimo una funzione che sia in grado di estrarre i termini significativi da una frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes(path):\n",
    "    quotes = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        quotes = f.readlines()\n",
    "    return quotes\n",
    "    \n",
    "def preprocess_quote(quote):\n",
    "    if '(' in quote:\n",
    "        quote = quote.replace('(', '').replace(')', '')\n",
    "    if '-' in quote:\n",
    "        for _ in range(quote.count('-')):\n",
    "            p = quote.find('-')\n",
    "            quote = quote[:p] + ' ' + quote[p+1:]\n",
    "    return quote.lower().strip('\\n')\n",
    "\n",
    "def extract_terms(quote):\n",
    "    terms = list()\n",
    "    for term in quote.split(' '):\n",
    "        term = preprocess_term(term)\n",
    "        if term is not None:\n",
    "            terms.append(term)\n",
    "    return terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione delle cinque parole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_words(path):\n",
    "    words = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        words = lines[randint(0,len(lines)-1)].strip('\\n').split(' ')\n",
    "    return words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risoluzione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La raccolta di modi di dire viene utilizzata per ricercare le cinque parole date, in modo da ottenere, per ciascuna parola, un insieme di frasi ad essa legate. I termini contenute in tali frasi vengono quindi utilizzati come insieme di contesto per ciascuna delle cinque parole date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contexts(words, path):\n",
    "    quotes = get_quotes(path)\n",
    "    res = {}\n",
    "    for word in words:\n",
    "        res[word] = set()\n",
    "\n",
    "    for quote in quotes:\n",
    "        quote = preprocess_quote(quote)\n",
    "        for word in words:\n",
    "            if word in quote.split(' '): \n",
    "                terms = extract_terms(quote)\n",
    "                res[word].update(terms)\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto è necessario contare le occorrenze nei cinque diversi insiemi di contesto per ciascuno dei termini. Se uno di essi dovesse essere uguale a una delle parole, è da escludere dai possibili risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_term_occurrences(context):\n",
    "    res = dict()\n",
    "    for word in context:\n",
    "        for term in context[word]:\n",
    "            if term in context:\n",
    "                continue\n",
    "            if term not in res:\n",
    "                res[term] = 0\n",
    "            res[term] += 1\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parola data in output dal sistema sarà il termine (o uno dei termini) che compare nel maggior numero di insiemi di contesto diversi. Il sistema dà in output anche il grado di confidenza, misurato come il numero di occorrenze del termine diviso 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five words where selected: ['tape', 'sky', 'letter', 'see', 'rag']\n",
      "The most probable word linked to the given five is: red, with confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "def execute(quotes_path, words_path):\n",
    "    words = select_words(words_path)\n",
    "    print(\"Five words where selected: {}\".format(words))\n",
    "    contexts = build_contexts(words, quotes_path)\n",
    "    terms = count_term_occurrences(contexts)\n",
    "    sorted_terms = sorted(terms.items(), key=lambda x: x[1], reverse=True)\n",
    "    for term in sorted_terms:\n",
    "        if term not in words:\n",
    "            print(\"The most probable word linked to the given five is: {}, with confidence: {}\".format(term[0], term[1]/5))\n",
    "            break\n",
    "\n",
    "execute(QUOTES_PATH, WORDS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiti del sistema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mancanza del Senso Comune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un forte limite del sistema è la mancata cattura di legami semantici dati dal senso comune, che è una diretta conseguenza dell'Ipotesi (2). Un modo per risolvere tale problema sarebbe quindi rilassarla. Per farlo si potrebbe migliorare la costruzione dell'insieme di contesto sfruttando risorse come ConceptNet per catturare anche il senso comune. In particolare, si potrebbero aggiungere a suddetto insieme di contesto, i nodi vicini (entro un certo raggio) alla parola cercata. \n",
    "Un esempio di questo limite è dato dalle cinque parole _friday, tires, travel, road, crash_. Qui un umano individua facilmente che la risposta è la parola _car_. Tuttavia non essendoci modi di dire che leghino le ultime 4 parole a _car_, il sistema attualmente non è in grado di trovare con sicurezza una sola parola. Per l'Ipotesi (3), esso restituisce comunque una parola, e può capitare che essa sia proprio _car_, ma solo perché viene selezionata casualmente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f51c5fe9e9a58efa1043b1548cfcb156c8f39c9e60365a17bc19defd3d30b528"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
